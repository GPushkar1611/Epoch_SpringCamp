{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b5a4517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ecca1e",
   "metadata": {},
   "source": [
    "### KNN Classification Task\n",
    "\n",
    "This dataset consists of fruits classified based on three features:\n",
    "\n",
    "1. **Weight (g)**: The weight of the fruit.\n",
    "2. **Size (cm)**: The size of the fruit.\n",
    "3. **Color**: Encoded as:\n",
    "   - `0`: Yellow\n",
    "   - `1`: Red\n",
    "   - `2`: Orange\n",
    "\n",
    "The goal is to implement the **K-Nearest Neighbors (KNN)** algorithm from scratch using only Python and NumPy to classify new fruit samples into one of three types:\n",
    "\n",
    "- **Apple**\n",
    "- **Banana**\n",
    "- **Orange**\n",
    "\n",
    "The dataset serves as training data for the KNN model, which will predict the fruit type for test samples based on feature similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "626a5efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [150, 7.0, 1, 'Apple'],\n",
    "    [120, 6.5, 0, 'Banana'],\n",
    "    [180, 7.5, 2, 'Orange'],\n",
    "    [155, 7.2, 1, 'Apple'],\n",
    "    [110, 6.0, 0, 'Banana'],\n",
    "    [190, 7.8, 2, 'Orange'],\n",
    "    [145, 7.1, 1, 'Apple'],\n",
    "    [115, 6.3, 0, 'Banana']\n",
    "]\n",
    "\n",
    "# Dictionary to encode fruit labels into numeric values\n",
    "label_encoding = {\n",
    "    'Apple': 0,\n",
    "    'Banana': 1,\n",
    "    'Orange': 2\n",
    "}\n",
    "\n",
    "# Replace the fruit type in each row with its corresponding numeric label\n",
    "for row in data:\n",
    "    row[3] = label_encoding[row[3]]\n",
    "\n",
    "# Convert the list of lists into a NumPy array for easier numerical processing\n",
    "data = np.array(data, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1f7c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, :-1]  # Features (all columns except the last one)\n",
    "y = data[:, -1]   # Labels (last column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b98589",
   "metadata": {},
   "source": [
    "### Euclidean Distance Function\n",
    "\n",
    "The `euclidean_distance` function calculates the straight-line distance between two points in a multi-dimensional space using the **Euclidean Distance formula**:\n",
    "$$\n",
    "d = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}\n",
    "$$\n",
    "Where:\n",
    "- $ x_i $ and $ y_i $ are the coordinates of the two points.\n",
    "\n",
    "#### Steps:\n",
    "1. **Convert Inputs to NumPy Arrays**:  \n",
    "   Ensures compatibility for vectorized operations.\n",
    "\n",
    "2. **Dimension Check**:  \n",
    "   Validates that both points have the same number of dimensions.\n",
    "\n",
    "3. **Squared Differences**:  \n",
    "   Calculates $ (x_i - y_i)^2 $ for each dimension.\n",
    "\n",
    "4. **Sum and Square Root**:  \n",
    "   Sums the squared differences and takes the square root to compute the distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ed3a41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(point1, point2):\n",
    "    # Convert inputs to numpy arrays for vectorized operations\n",
    "    point1 = np.array(point1)\n",
    "    point2 = np.array(point2)\n",
    "    \n",
    "    # Check if points have the same dimensions\n",
    "    if point1.shape != point2.shape:\n",
    "        raise ValueError(\"Points must have the same dimensions\")\n",
    "    \n",
    "    # Calculate squared differences\n",
    "    squared_diff = (point1 - point2) ** 2\n",
    "    \n",
    "    # Sum the squared differences and take the square root\n",
    "    distance = np.sqrt(np.sum(squared_diff))\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3aa66a",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN) Implementation\n",
    "\n",
    "This code implements the K-Nearest Neighbors algorithm.\n",
    "\n",
    "1. **Stores** all training examples without building a model (lazy learning)\n",
    "2. **Classifies** new instances based on similarity to known examples\n",
    "\n",
    "#### Algorithm Steps:\n",
    "- **Training**: Simply stores labeled data points\n",
    "- **Prediction**: For each test sample:\n",
    "  1. Calculate distances to all training points\n",
    "  2. Find k closest neighbors\n",
    "  3. Use majority vote to determine class\n",
    "\n",
    "#### Key Components:\n",
    "- **`__init__(k=3)`**: Sets the number of neighbors to consider\n",
    "- **`fit(X, y)`**: Stores training data without computation\n",
    "- **`predict(X_test)`**: Processes multiple samples in batch\n",
    "- **`predict_one(x)`**: Core logic for a single prediction:\n",
    "  - Calculates distances using Euclidean metric\n",
    "  - Selects k nearest points using `np.argsort`\n",
    "  - Determines majority class with `Counter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "911a6ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        # Initialize with default k=3 neighbors to consider\n",
    "        self.k = k\n",
    "        self.X_train = None  # Will store training features\n",
    "        self.y_train = None  # Will store training labels\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Store training data (KNN doesn't actually \"train\" - just memorizes data)\n",
    "        self.X_train = np.array(X)\n",
    "        self.y_train = np.array(y)\n",
    "        return self  # Return instance for method chaining\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        # Convert input to numpy array and predict labels for all test samples\n",
    "        X_test = np.array(X_test)\n",
    "        # Get prediction for each test sample using list comprehension\n",
    "        predictions = np.array([self.predict_one(x) for x in X_test])\n",
    "        return predictions\n",
    "    \n",
    "    def predict_one(self, x):\n",
    "        # Calculate Euclidean distance between test sample and all training samples\n",
    "        distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "        \n",
    "        # Get indices of k smallest distances using argsort\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        \n",
    "        # Extract labels of the nearest neighbors using the indices\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        \n",
    "        # Return most frequent label using Counter's majority vote\n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        return most_common[0][0]  # Return tuple's first element (label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9f8b3c",
   "metadata": {},
   "source": [
    "### Using KNN for Fruit Classification\n",
    "\n",
    "This code demonstrates how to apply the KNN model to classify new fruit samples:\n",
    "\n",
    "#### Test Data:\n",
    "The test data contains three fruit samples with features:\n",
    "- **Sample 1**: Weight=118g, Size=6.2cm, Yellow color (0) → Expected: Banana\n",
    "- **Sample 2**: Weight=160g, Size=7.3cm, Red color (1) → Expected: Apple  \n",
    "- **Sample 3**: Weight=185g, Size=7.7cm, Orange color (2) → Expected: Orange\n",
    "\n",
    "#### Prediction Process:\n",
    "1. **Instantiate**: Create KNN classifier with k=3\n",
    "2. **Train**: Store the training dataset using `fit()`\n",
    "3. **Predict**: For each test sample:\n",
    "   - Calculate distances to all training points\n",
    "   - Find 3 nearest neighbors\n",
    "   - Assign majority class via voting\n",
    "\n",
    "#### Output Processing:\n",
    "- Convert numeric predictions (0,1,2) to fruit names using a dictionary\n",
    "- Compare predictions with expected values to verify accuracy\n",
    "\n",
    "The k=3 parameter means each prediction is based on the 3 most similar fruits from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60b190f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted fruits: ['Banana', 'Apple', 'Orange']\n",
      "Expected fruits: ['Banana', 'Apple', 'Orange']\n"
     ]
    }
   ],
   "source": [
    "# Test data:\n",
    "test_data = np.array([\n",
    "    [118, 6.2, 0],  # Expected: Banana\n",
    "    [160, 7.3, 1],  # Expected: Apple\n",
    "    [185, 7.7, 2]   # Expected: Orange\n",
    "])\n",
    "\n",
    "# Create an instance of the KNN classifier with k=3 (we have set it as default in the class)\n",
    "knn = KNN()\n",
    "\n",
    "# Fit the model using training data (X: features, y: labels)\n",
    "knn.fit(X, y)\n",
    "\n",
    "# Predict labels for the test data using the trained KNN model\n",
    "predictions = knn.predict(test_data)\n",
    "\n",
    "# Map numeric labels to corresponding fruit names for better readability\n",
    "fruit_names = {0: \"Apple\", 1: \"Banana\", 2: \"Orange\"}\n",
    "predicted_fruits = [fruit_names[label] for label in predictions]\n",
    "\n",
    "# Print predicted fruit types and expected fruit types for comparison\n",
    "print(\"\\nPredicted fruits:\", predicted_fruits)\n",
    "print(\"Expected fruits: ['Banana', 'Apple', 'Orange']\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
